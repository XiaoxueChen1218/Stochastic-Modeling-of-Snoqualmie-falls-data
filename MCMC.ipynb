{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intensive-galaxy",
   "metadata": {},
   "source": [
    "### MCMC\n",
    "**(1)**\n",
    "\n",
    "Using the multiple years of data estimate the transition probability matrix for the first-order Markov chain model, with $p_{12}$, the probability of wet given dry and $p_{21}$, the probability of dry given wet. Obtain MLEs and 95\\% asymptotic confidence intervals for $p_{12}$ and $p_{21}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "spectacular-swing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transitions are: \n",
      "0 to 0: 626 0 to 1: 424 \n",
      "1 to 0: 425 1 to 1: 1738\n",
      "MLE are: \n",
      "0 to 0: 0.5962 0 to 1: 0.4038 \n",
      "1 to 0: 0.1965 1 to 1: 0.8035\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "my_file = open(\"snoqualmie_falls.txt\", \"r\")\n",
    "content = my_file.read().splitlines()\n",
    "obs = []\n",
    "for temp in content:\n",
    "    temp_list = temp.split()\n",
    "    obs += temp_list\n",
    "    \n",
    "## get observations in Jan (be aware of Leap years)\n",
    "month_years = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "month_leap_years = [31,29,31,30,31,30,31,31,30,31,30,31]\n",
    "Q1_days = [0,31+28+31]\n",
    "Q1_leap_days  = [0,31+29+31]\n",
    "\n",
    "## observations in the first quarter\n",
    "Q1_obs = []\n",
    "days = 0\n",
    "for i in range(1948,1984):\n",
    "    if (i % 4 == 0):\n",
    "        temp = obs[(days+Q1_leap_days[0]):(days+Q1_leap_days[1])]\n",
    "        temp = list(map(int, temp))\n",
    "        Q1_obs.append(temp)\n",
    "        days += 366\n",
    "    else:\n",
    "        temp = obs[(days+Q1_days[0]):(days+Q1_days[1])]\n",
    "        temp = list(map(int, temp))\n",
    "        Q1_obs.append(temp)\n",
    "        days += 365 \n",
    "        \n",
    "## count transition types \n",
    "n11 = n10 = n01 = n00 = 0\n",
    "for i in range(36):\n",
    "    temp = Q1_obs[i]\n",
    "    for j in range(len(temp)-1):\n",
    "        if (temp[j] == 0 and temp[j+1] == 0):\n",
    "            n00 += 1\n",
    "        elif (temp[j] == 0 and temp[j+1] > 0):\n",
    "            n01 += 1\n",
    "        elif (temp[j] > 0 and temp[j+1] == 0):\n",
    "            n10 += 1\n",
    "        else:\n",
    "            n11 += 1\n",
    "print(\"transitions are: \\n0 to 0: \" + str(n00) + \" 0 to 1: \" + str(n01) + \" \\n1 to 0: \" + str(n10) + \" 1 to 1: \" + str(n11))\n",
    "\n",
    "p01 = n01/(n00+n01)\n",
    "p10 = n10/(n11+n10)\n",
    "p00 = n00/(n00 + n01)\n",
    "p11 = n11/(n11 + n10)\n",
    "\n",
    "print(\"MLE are: \\n0 to 0: \" + str(np.round(p00,4)) + \" 0 to 1: \" + str(np.round(p01,4)) + \" \\n1 to 0: \" + str(np.round(p10,4)) + \" 1 to 1: \" + str(np.round(p11,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-handling",
   "metadata": {},
   "source": [
    "Thus the point estimates are $\\hat{p}_{12, MLE} \\approx 0.4038$, $\\hat{p}_{21, MLE} \\approx 0.1965$.\n",
    "\n",
    "\n",
    "To calculate the asymptotic $95\\%$ confidence interval for $\\hat{p}_{12, MLE}$ and $\\hat{p}_{21, MLE}$, use the asymptotic normality property of the MLE estimate(this should hold since the markov chain is of finite states and irreducible):\n",
    "\n",
    "$$\n",
    "\\frac{\\hat{p}_{ij} - p_{ij}}{\\sqrt{p_{ij}(1-p_{ij})}}\\sqrt{n\\pi_i} \\xrightarrow{\\text{D}}N(0,1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "common-frank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for p12: ( 0.3742 , 0.4335 )\n",
      "95% confidence interval for p21: ( 0.1797 , 0.2132 )\n"
     ]
    }
   ],
   "source": [
    "## solving the stationary distribution\n",
    "tpm = np.array([[p00, p01],[p10, p11]])\n",
    "A_temp = np.transpose(tpm) - np.identity(2)\n",
    "A = np.vstack([A_temp[1],np.ones(2)])\n",
    "#A = np.array(tpm[1], np.ones(2))\n",
    "b = np.array([0,1])\n",
    "pi_hat = np.linalg.solve(A,b)\n",
    "n_total = n00 + n10 + n01 + n11\n",
    "std_01 = np.sqrt(tpm[0,1]*(1-tpm[0,1]))/np.sqrt(n_total)/np.sqrt(pi_hat[0])\n",
    "std_10 = np.sqrt(tpm[1,0]*(1-tpm[1,0]))/np.sqrt(n_total)/np.sqrt(pi_hat[1])\n",
    "# CI for p12\n",
    "print(\"95% confidence interval for p12: (\", str(np.round(p01 - 1.96*std_01,4)), \",\", str(np.round(p01 + 1.96*std_01,4)), \")\")\n",
    "# CI for p21\n",
    "print(\"95% confidence interval for p21: (\", str(np.round(p10 - 1.96*std_10,4)), \",\", str(np.round(p10 + 1.96*std_10,4)), \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-cancer",
   "metadata": {},
   "source": [
    "$$\n",
    "p_{i j} \\in\\left[\\hat{p}_{i j}-z_{1-\\alpha / 2} \\frac{\\sqrt{\\hat{p}_{i j}\\left(1-\\hat{p}_{i j}\\right)}}{\\sqrt{n \\hat{\\pi}_{i}}}, \\hat{p}_{i j}+z_{1-\\alpha / 2} \\frac{\\sqrt{\\hat{p}_{i j}\\left(1-\\hat{p}_{i j}\\right)}}{\\sqrt{n \\hat{\\pi}_{i}}}\\right]\n",
    "$$\n",
    "\n",
    "Thus the confidence interval for $p_{12}, p_{21}$ are $( 0.3742 , 0.4335 )$ and $( 0.1797 , 0.2132 )$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-identity",
   "metadata": {},
   "source": [
    "**(b)**\n",
    "\n",
    "Under the assumption of independent uniform priors, give the\n",
    "\tform of the posterior distributions for the parameters\n",
    "\t$p_{12},p_{21}$. Obtain the posterior and report posterior medians\n",
    "\tand 95\\% credible intervals for each of the two parameters. (use any package to compute the inverse of the cumulative distribution of the posterior to find the median and the credible interval).\n",
    "\n",
    "\n",
    "**Solution:**\n",
    "Notice that for each row in tpm, we have\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p_{i 1}, p_{i 2} & \\sim \\operatorname{Dirichlet}(1,1), \\quad i=1,2 \\\\\n",
    "\\left(p_{11}, p_{12}\\right) &\\perp\\left(p_{21}, p_{22}\\right) \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Since \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\pi\\left(p_{i} \\mid X_{1}, \\ldots, X_{n}\\right) & \\propto p_{i 1}^{n_{i 1}+1-1} p_{i 2}^{n_{i 2}+1-1}, \\quad i=1,2 \\\\\n",
    "p_{i} \\mid X_{1}, \\ldots, X_{n} & \\sim \\operatorname{Dirichlet}\\left(n_{i 1}+1, n_{i 2}+1\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "As we have $n_{12} = 424, n_{21} = 425$, the posterior distributions are \n",
    "\n",
    "$$\n",
    "p_{12}\\left|X_{1}, \\ldots, X_{n} \\sim \\operatorname{Beta}(n_{12} + 1, n_{11} + 1),\\left(p_{21}\\right)\\right| X_{1}, \\ldots, X_{n} \\sim \\operatorname{Beta}(n_{21}+1, n_{22} + 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "recovered-people",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% posterior credible interval for p_12: ( 0.375,0.434 )\n",
      "95% posterior credible interval for p_21: ( 0.18,0.214 )\n",
      "posterior median for p_12: 0.4039\n",
      "posterior median for p_21: 0.1967\n"
     ]
    }
   ],
   "source": [
    "rv_12 = sp.stats.beta(n01 + 1, n00 + 1)\n",
    "rv_21 = sp.stats.beta(n10 + 1, n11 + 1)\n",
    "print(\"95% posterior credible interval for p_12: ( \" + str(np.round(rv_12.ppf(0.025),3)) +\n",
    "     \",\" + str(np.round(rv_12.ppf(0.975),3)), \")\")\n",
    "print(\"95% posterior credible interval for p_21: ( \" + str(np.round(rv_21.ppf(0.025),3)) +\n",
    "     \",\" + str(np.round(rv_21.ppf(0.975),3)), \")\")\n",
    "print(\"posterior median for p_12: \" + str(np.round(rv_12.ppf(0.5),4)))\n",
    "print(\"posterior median for p_21: \" + str(np.round(rv_21.ppf(0.5),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-wednesday",
   "metadata": {},
   "source": [
    "**(c)**\n",
    "Read carefully Sec. 11.5 of Lecture 11, test the independence of the data in a frequentist and a Bayesian viewpoint (for the Bayesian viewpoint you can use the prior of your choice).\n",
    "\n",
    "Conduct the hypothesis test of independent samples against Markov chain samples. Notice that the formula of likelihood ratio is given by\n",
    "\n",
    "$$\n",
    "T_{n}=2\\left(l_{n}\\left(\\hat{\\boldsymbol{P}}_{M L E}\\right)-l_{n}\\left(\\hat{\\boldsymbol{P}}_{M L E, 0}\\right)\\right)=2 \\sum_{i=1}^{2} \\sum_{j=1}^{2} n_{i j} \\log \\left(\\frac{n_{i j} \\cdot n}{n_{i+} \\cdot n_{+j}}\\right)=501.945\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "olive-mistake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501.9457978794331"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = n00*(np.log(n00) + np.log(n_total) - np.log(n01 + n00) - np.log(n00 + n10)) + n01*(np.log(n01) + np.log(n_total) - np.log(n01 + n00) - np.log(n01 + n11))+ n10*(np.log(n10) + np.log(n_total) - np.log(n10 + n11) - np.log(n00 + n10))+ n11*(np.log(n11) + np.log(n_total) - np.log(n10 + n11) - np.log(n01 + n11))\n",
    "T *= 2\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abroad-december",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv_chisq = sp.stats.chi(1)\n",
    "1-rv_chisq.cdf(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-romania",
   "metadata": {},
   "source": [
    "Thus we reject the null hypothesis that the data are IID samples with at least 95 % confidence.\n",
    "To conduct this test under Bayesian prospective, pose a uniform distribution on the each row of the transition probability matrix and assume independence between two rows. The Bayes factor is given by\n",
    "\n",
    "$$\n",
    "B F=\\frac{B\\left(n_{+1}+1, n_{+2}+1\\right) / B(1,1)}{\\prod_{i=1}^{2}\\left[B\\left(n_{i 1}+1, n_{i 2}+1\\right) / B(1,1)\\right]} \\approx 2.577 \\times 10^{-108}\n",
    "$$\n",
    "\n",
    "The Bayes factor is extremely close to zero, suggesting that the data is not independent. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
